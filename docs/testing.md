# Test coverage
The most important parts of the project are the graph library (graphs.nim), the vector/math library (geometry.nim), the level format (levels.nim) and the game itself (game.nim). These are tested with good unit test 
coverage. Keep in mind that the coverage generation tool I use has bugged line coverage and only the function coverage is accurate. The rest of the source files are about graphics, UI and user interaction. 

The graph library was tested by making a graph of a 5x5 grid with the nodes not connected to anything at first. Then I connected all the nodes and separated 3 nodes completely from the rest of the graph. The graph was 
checked after almost every change. At the end of the test I check that route existence checking and finding connected nodes works. The graph library test also tests some of the functions in geometry.nim when creating the
grid.

The level format and level editing library is tested by generating a test level with it and saving it to disk. Then the level is loaded from the file and the level object is checked to be equal to the one created in memory.
The test doesn't check that the level editing functions return expected results. This is definitely a flaw in my testing. However level solution tests use the generated levels to test a bunch of complicated puzzle 
solutions in the levels, so this isn't that big of an issue.

In this project the algorithms are implemented correctly if the symbols follow the same rules as in The Witness. There are many complex interactions between different symbol types so this project will necessarily have some
edge cases that don't follow the same rules. However all the currently playable levels are all tested and I currently  haven't found any rules that are not implemented correctly. The game implementation is tested by running
a bunch of correct and incorrect solutions for each of the levels through the solution checking algorithm. The test checks that the algorithm accepts all correct solutions and denies all incorrect ones. This test also
doubles as a performance test when compiled by the measurePerf flag (see user_guide.md on how to run perf test). The functions used for making sure the line doesn't overlap and the points are in order are not tested.
All the correct and incorrect solutions in the test were generated by me playing the levels in game and pressing P so those parts have gotten plenty of manual testing. (Pressing P after drawing a correct or incorrect
solution prints out the line as text.)

The test coverage report can be found on [Github pages](https://cloudperry.github.io/the-witness-puzzle-maker/coverage/index.html).

# Performance testing results
The most performance critical part of this project is the level solution checking algorithm and the performance tests focus on that. The solution checking algorithm should run fast so that the player can be instantly told, if a solution was correct or not. I have also tested bigger levels for understanding the time complexity of the solution checker, but those results are in the implementation document. This testing focuses on whether the
solution checker is fast enough in real game levels. They are usually pretty small, because the symbols can make even small levels pretty hard to solve.

Release build performance:
```
level solution checking algorithm (game.nim) tests ran successfully in 8313 µs.
per-level times: {"entryarea-secretdoor": 1499, "treehouse-yellowbridge-puzzle8": 211, "treehouse-purplebridge-puzzle9": 184, "quarry-boathouse-metalplatform-panel7": 272, "hex-tutorial1": 74, "quarry-metalplatform-panel2": 119, "shipwreck-triangles": 153, "hex-tutorial2": 179, "treehouse-top-orangebridge-puzzle4": 230, "treehouse-purplebridge-puzzle11": 394, "swamp-redpanel4": 4998}
```

Release build performance with runtime safety checks off (default of nimble perftest command that I made in the package):
```
level solution checking algorithm (game.nim) tests ran successfully in 208 µs.
per-level times: {"entryarea-secretdoor": 59, "treehouse-yellowbridge-puzzle8": 11, "treehouse-purplebridge-puzzle9": 11, "quarry-boathouse-metalplatform-panel7": 18, "hex-tutorial1": 7, "quarry-metalplatform-panel2": 11, "shipwreck-triangles": 14, "hex-tutorial2": 10, "treehouse-top-orangebridge-puzzle4": 18, "treehouse-purplebridge-puzzle11": 22, "swamp-redpanel4": 27}
```

I have quite a fast processor, but still the release build is clearly fast enough as this is a puzzle game where high framerates don't matter much. The slowest level takes 5 milliseconds to check both one correct and one
incorrect solution. A new frame has to be ready in around 16 milliseconds if the game were to target 60 fps. There are quite a bit more complex levels in The Witness (for the solution checker) than the current slowest level
, but I'm sure there is enough headroom that these levels could work with these algorithms. The release build with runtime safety checks is surprisingly fast and is able to check many solutions for all the currently
playable levels in under half a millisecond. I suspect that Nim's runtime safety checks somehow completely wreck parallelisation done by the processor for some important part of the algorithm.

# Running the tests
Follow the steps in [User guide](docs/user_guide.md) to install Nim and to switch to devel version of Nim. Running tests and other project actions are also described in that document.
